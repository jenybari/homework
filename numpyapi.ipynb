{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        date  \\\n",
      "0   2022-03-02T14:24:21.000Z   \n",
      "1   2022-03-02T14:00:31.000Z   \n",
      "2   2022-03-02T12:18:37.000Z   \n",
      "3   2022-03-02T11:11:11.000Z   \n",
      "4   2022-03-02T10:47:00.000Z   \n",
      "5   2022-03-02T09:08:54.000Z   \n",
      "6   2022-03-02T08:48:08.000Z   \n",
      "7   2022-03-02T08:37:40.000Z   \n",
      "8   2022-03-02T08:00:03.000Z   \n",
      "9   2022-03-02T07:08:14.000Z   \n",
      "10  2022-03-02T06:50:25.000Z   \n",
      "11  2022-03-02T04:17:52.000Z   \n",
      "12  2022-03-02T10:47:00.000Z   \n",
      "13  2022-03-02T09:08:54.000Z   \n",
      "\n",
      "                                                title  \\\n",
      "0     О Thread и ThreadPool в .NET подробно (часть 2)   \n",
      "1     О Thread и ThreadPool в .NET подробно (часть 1)   \n",
      "2               Не самые популярные методы Django ORM   \n",
      "3           Недельный геймдев: #59 — 27 февраля, 2022   \n",
      "4   Сочетание Shift-Left и «Традиционной» модели т...   \n",
      "5   По новым рельсам: как Страховой Дом ВСК запуст...   \n",
      "6   Приватность в электронной почте: нам нужно исп...   \n",
      "7   Flutter: простыми словами про ассинхронность и...   \n",
      "8   Облегчаем работу с SQL в go и при этом не отст...   \n",
      "9   Откровения про отсутствующий Nested Inline от ...   \n",
      "10                   Краткая история одного внедрения   \n",
      "11    Как запустить канал на YouTube, если ты инвалид   \n",
      "12  Сочетание Shift-Left и «Традиционной» модели т...   \n",
      "13  По новым рельсам: как Страховой Дом ВСК запуст...   \n",
      "\n",
      "                                                 link  \\\n",
      "0                    https://habr.com/ru/post/654111/   \n",
      "1                    https://habr.com/ru/post/654101/   \n",
      "2       https://habr.com/ru/company/otus/blog/654081/   \n",
      "3                    https://habr.com/ru/post/654071/   \n",
      "4       https://habr.com/ru/company/cian/blog/654067/   \n",
      "5   https://habr.com/ru/company/vsk_insurance/blog...   \n",
      "6                    https://habr.com/ru/post/653965/   \n",
      "7                    https://habr.com/ru/post/654047/   \n",
      "8      https://habr.com/ru/company/first/blog/652697/   \n",
      "9                    https://habr.com/ru/post/651179/   \n",
      "10                   https://habr.com/ru/post/654037/   \n",
      "11    https://habr.com/ru/company/itsoft/blog/654021/   \n",
      "12      https://habr.com/ru/company/cian/blog/654067/   \n",
      "13  https://habr.com/ru/company/vsk_insurance/blog...   \n",
      "\n",
      "                                                 text  \n",
      "0   В предыдущей публикации мы рассмотрели некотор...  \n",
      "1   Ссылка на Часть 2: \"О Thread и ThreadPool в .N...  \n",
      "2   Все мы знаем, что Django предоставляет ORM пря...  \n",
      "3   Из новостей: Epic Games выпустила превью-верси...  \n",
      "4   В этом материале будет кратко рассказано, поче...  \n",
      "5   О переходе на Agile-практики и Scrum на Хабре ...  \n",
      "6   \\nСвязь по электронной почте\\r\\nВ наши дни свя...  \n",
      "7   Всем привет, читатели Habr! В этой статье я хо...  \n",
      "8   \\r\\nПродолжаю серию статей по программированию...  \n",
      "9   \\n\\n — Стыдно признаться, но в нашей компании ...  \n",
      "10   Просматривая страницы на Хабре, я наткнулся н...  \n",
      "11  Привет всем! Меня зовут Станислав, я фрилансер...  \n",
      "12  В этом материале будет кратко рассказано, поче...  \n",
      "13  О переходе на Agile-практики и Scrum на Хабре ...  \n"
     ]
    }
   ],
   "source": [
    "KEYWORDS = ['тест', 'истории']\n",
    "page_link = 'https://habr.com/ru/all/'\n",
    "base_link = 'https://habr.com'\n",
    "\n",
    "def get_habr_articles(page_link):\n",
    "    res = requests.get(page_link)\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    articles = soup.findAll('div', 'tm-article-snippet')\n",
    "    return articles\n",
    "\n",
    "def get_articles_data(articles, base_link):\n",
    "    df = pd.DataFrame()\n",
    "    for article in articles:\n",
    "        title = article.find('a', 'tm-article-snippet__title-link').find('span').text\n",
    "        date = article.find('span', 'tm-article-snippet__datetime-published').find('time').get('datetime')\n",
    "        link = base_link + article.find('a', 'tm-article-snippet__title-link').get('href')\n",
    "        res_article = requests.get(link)\n",
    "        soup_article = BeautifulSoup(res_article.text, features='lxml')\n",
    "        text = soup_article.find('div', 'article-formatted-body').find('div').text\n",
    "        row = {'date' : date, 'title' : title, 'link' : link, 'text' : text}\n",
    "        df = pd.concat([df, pd.DataFrame([row])]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def get_filtered_articles_data(df, keywords):\n",
    "    fitered_df = pd.DataFrame()\n",
    "    for keyword in keywords:\n",
    "        fitered_df_by_one_keyword = df[df.title.str.contains(keyword) | df.text.str.contains(keyword)]\n",
    "        fitered_df = pd.concat([fitered_df, fitered_df_by_one_keyword])\n",
    "    return fitered_df.reset_index(drop=True)\n",
    "\n",
    "articles = get_habr_articles(page_link)\n",
    "df = get_articles_data(articles, base_link)\n",
    "fitered_df = get_filtered_articles_data(df, KEYWORDS)\n",
    "\n",
    "print(fitered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   data            source  \\\n",
      "0  2016-11-01T00:00:00Z            qip.ru   \n",
      "1  2017-02-14T00:00:00Z    parapa.mail.ru   \n",
      "2  2016-10-29T00:00:00Z            vk.com   \n",
      "3  2016-10-21T00:00:00Z         adobe.com   \n",
      "4  2017-02-14T00:00:00Z     cfire.mail.ru   \n",
      "5  2017-01-31T00:00:00Z  cdprojektred.com   \n",
      "6  2016-10-23T00:00:00Z         imesh.com   \n",
      "\n",
      "                                         description  \n",
      "0  In 2011, Russian instant messaging service pro...  \n",
      "1  In July and August 2016, two criminals execute...  \n",
      "2  Popular Russian social networking platform VKo...  \n",
      "3  In October of 2013, criminals penetrated Adobe...  \n",
      "4  In July and August of 2016, two criminals carr...  \n",
      "5  In March 2016, CDProjektRed.com.com's forum da...  \n",
      "6  In June 2016, a cache of over 51 million user ...  \n"
     ]
    }
   ],
   "source": [
    "url = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
    "EMAIL = ['xxx@x.ru', 'yyy@y.ru']\n",
    "headers_ = {\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36',\n",
    "    'Vaar-Header-App-Build-Version': '1.0.0',\n",
    "    'Vaar-Header-App-Product-Name': 'hackcheck-web-avast',\n",
    "    'Vaar-Version': '0'\n",
    "}\n",
    "json_ = {\n",
    "    'emailAddresses': EMAIL\n",
    "}\n",
    "res = requests.post(url, json=json_, headers=headers_).json()['breaches']\n",
    "df2 = pd.DataFrame()\n",
    "for (key, value) in res.items():\n",
    "    row = {'data' : value['publishDate'], 'source' : value['site'], 'description' : value['description']}\n",
    "    df2 = pd.concat([df2, pd.DataFrame([row])]).reset_index(drop=True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
